{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "Lottery.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a572315-970e-4743-b21d-d470c1eefac9"
      },
      "source": [
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch"
      ],
      "id": "8a572315-970e-4743-b21d-d470c1eefac9",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ac721c5-22ed-4bea-9491-0f3d0fc6b46c"
      },
      "source": [
        "?FashionMNIST"
      ],
      "id": "8ac721c5-22ed-4bea-9491-0f3d0fc6b46c",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "937ebf3e-26ff-417a-911f-a2444bc9bee5"
      },
      "source": [
        "datadir=\"data\"\n",
        "train_data = FashionMNIST(root=datadir, train=True, download=True, transform=ToTensor())\n",
        "test_data = FashionMNIST(root=datadir, train=False, download=True, transform=ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data,batch_size=32)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1)"
      ],
      "id": "937ebf3e-26ff-417a-911f-a2444bc9bee5",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b3ab9cb-9feb-428f-b2a3-6481db1ae6ca"
      },
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n"
      ],
      "id": "8b3ab9cb-9feb-428f-b2a3-6481db1ae6ca",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9431474-dc89-4590-93dc-790d55a55405"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "def log_layer_weights(model):\n",
        "  print(f\"conv1: {model.conv1.weight.shape}\")\n",
        "  print(f\"conv2: {model.conv2.weight.shape}\")\n",
        "  print(f\"fc1: {model.fc1.weight.shape}\")\n",
        "  print(f\"fc1: {model.fc2.weight.shape}\")\n",
        "\n",
        "\n",
        "def train( model, device, train_loader, optimizer, epoch, log_interval=10):\n",
        "    model.train()\n",
        "    log_layer_weights(model)\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "id": "f9431474-dc89-4590-93dc-790d55a55405",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEvBCKdzvvVE"
      },
      "source": [
        "LR=0.001\n",
        "GAMMA=0.7\n",
        "EPOCHS=2\n",
        "device=\"cuda\"\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=LR)\n"
      ],
      "id": "sEvBCKdzvvVE",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63e1473d-131a-4479-8a82-032509d2f9fa",
        "outputId": "0506517e-6858-478b-9f49-fd570547a4b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=GAMMA)\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), \"mnist_cnn.pt\")"
      ],
      "id": "63e1473d-131a-4479-8a82-032509d2f9fa",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1: torch.Size([32, 1, 3, 3])\n",
            "conv2: torch.Size([64, 32, 3, 3])\n",
            "fc1: torch.Size([128, 9216])\n",
            "fc1: torch.Size([10, 128])\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298222\n",
            "Train Epoch: 1 [320/60000 (1%)]\tLoss: 2.282948\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.288045\n",
            "Train Epoch: 1 [960/60000 (2%)]\tLoss: 2.324362\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.292611\n",
            "Train Epoch: 1 [1600/60000 (3%)]\tLoss: 2.286153\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.314161\n",
            "Train Epoch: 1 [2240/60000 (4%)]\tLoss: 2.290479\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.291435\n",
            "Train Epoch: 1 [2880/60000 (5%)]\tLoss: 2.329471\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.278800\n",
            "Train Epoch: 1 [3520/60000 (6%)]\tLoss: 2.276107\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.270518\n",
            "Train Epoch: 1 [4160/60000 (7%)]\tLoss: 2.274452\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.284772\n",
            "Train Epoch: 1 [4800/60000 (8%)]\tLoss: 2.287857\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.291194\n",
            "Train Epoch: 1 [5440/60000 (9%)]\tLoss: 2.302172\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.274741\n",
            "Train Epoch: 1 [6080/60000 (10%)]\tLoss: 2.272276\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.283109\n",
            "Train Epoch: 1 [6720/60000 (11%)]\tLoss: 2.287696\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.291409\n",
            "Train Epoch: 1 [7360/60000 (12%)]\tLoss: 2.297312\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.272876\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.285399\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.269263\n",
            "Train Epoch: 1 [8640/60000 (14%)]\tLoss: 2.262506\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.269424\n",
            "Train Epoch: 1 [9280/60000 (15%)]\tLoss: 2.280621\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.269112\n",
            "Train Epoch: 1 [9920/60000 (17%)]\tLoss: 2.255482\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.246716\n",
            "Train Epoch: 1 [10560/60000 (18%)]\tLoss: 2.234852\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.251844\n",
            "Train Epoch: 1 [11200/60000 (19%)]\tLoss: 2.242344\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.262594\n",
            "Train Epoch: 1 [11840/60000 (20%)]\tLoss: 2.249750\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.235718\n",
            "Train Epoch: 1 [12480/60000 (21%)]\tLoss: 2.240193\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.249791\n",
            "Train Epoch: 1 [13120/60000 (22%)]\tLoss: 2.243889\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.233560\n",
            "Train Epoch: 1 [13760/60000 (23%)]\tLoss: 2.237143\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.225648\n",
            "Train Epoch: 1 [14400/60000 (24%)]\tLoss: 2.223248\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.236465\n",
            "Train Epoch: 1 [15040/60000 (25%)]\tLoss: 2.222623\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.210852\n",
            "Train Epoch: 1 [15680/60000 (26%)]\tLoss: 2.214670\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.228090\n",
            "Train Epoch: 1 [16320/60000 (27%)]\tLoss: 2.237268\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.201717\n",
            "Train Epoch: 1 [16960/60000 (28%)]\tLoss: 2.187172\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.211032\n",
            "Train Epoch: 1 [17600/60000 (29%)]\tLoss: 2.175878\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.159475\n",
            "Train Epoch: 1 [18240/60000 (30%)]\tLoss: 2.216548\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.230792\n",
            "Train Epoch: 1 [18880/60000 (31%)]\tLoss: 2.212197\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.192805\n",
            "Train Epoch: 1 [19520/60000 (33%)]\tLoss: 2.218140\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.183382\n",
            "Train Epoch: 1 [20160/60000 (34%)]\tLoss: 2.196765\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.142473\n",
            "Train Epoch: 1 [20800/60000 (35%)]\tLoss: 2.188579\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.150203\n",
            "Train Epoch: 1 [21440/60000 (36%)]\tLoss: 2.195164\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.161552\n",
            "Train Epoch: 1 [22080/60000 (37%)]\tLoss: 2.216298\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.146391\n",
            "Train Epoch: 1 [22720/60000 (38%)]\tLoss: 2.173482\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.208840\n",
            "Train Epoch: 1 [23360/60000 (39%)]\tLoss: 2.152057\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 2.135217\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 2.186071\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.155100\n",
            "Train Epoch: 1 [24640/60000 (41%)]\tLoss: 2.107852\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 2.099143\n",
            "Train Epoch: 1 [25280/60000 (42%)]\tLoss: 2.124181\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.148506\n",
            "Train Epoch: 1 [25920/60000 (43%)]\tLoss: 2.155474\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 2.112505\n",
            "Train Epoch: 1 [26560/60000 (44%)]\tLoss: 2.107291\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.095099\n",
            "Train Epoch: 1 [27200/60000 (45%)]\tLoss: 2.145987\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 2.108638\n",
            "Train Epoch: 1 [27840/60000 (46%)]\tLoss: 2.149619\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 2.105334\n",
            "Train Epoch: 1 [28480/60000 (47%)]\tLoss: 2.151938\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.087263\n",
            "Train Epoch: 1 [29120/60000 (49%)]\tLoss: 2.152138\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 2.152100\n",
            "Train Epoch: 1 [29760/60000 (50%)]\tLoss: 2.126150\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 2.109349\n",
            "Train Epoch: 1 [30400/60000 (51%)]\tLoss: 2.057625\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 2.025621\n",
            "Train Epoch: 1 [31040/60000 (52%)]\tLoss: 2.029600\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 2.043870\n",
            "Train Epoch: 1 [31680/60000 (53%)]\tLoss: 2.123488\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.067861\n",
            "Train Epoch: 1 [32320/60000 (54%)]\tLoss: 2.067488\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 1.975718\n",
            "Train Epoch: 1 [32960/60000 (55%)]\tLoss: 2.036805\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 2.082215\n",
            "Train Epoch: 1 [33600/60000 (56%)]\tLoss: 2.076449\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 2.014881\n",
            "Train Epoch: 1 [34240/60000 (57%)]\tLoss: 2.015013\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 2.015524\n",
            "Train Epoch: 1 [34880/60000 (58%)]\tLoss: 1.977183\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 1.969134\n",
            "Train Epoch: 1 [35520/60000 (59%)]\tLoss: 1.904511\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 2.012971\n",
            "Train Epoch: 1 [36160/60000 (60%)]\tLoss: 2.005651\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 1.965552\n",
            "Train Epoch: 1 [36800/60000 (61%)]\tLoss: 2.038019\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 1.898063\n",
            "Train Epoch: 1 [37440/60000 (62%)]\tLoss: 2.009273\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 1.918483\n",
            "Train Epoch: 1 [38080/60000 (63%)]\tLoss: 1.958971\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.985945\n",
            "Train Epoch: 1 [38720/60000 (65%)]\tLoss: 1.969494\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 1.934157\n",
            "Train Epoch: 1 [39360/60000 (66%)]\tLoss: 1.914719\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 1.949552\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 1.955248\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 1.902229\n",
            "Train Epoch: 1 [40640/60000 (68%)]\tLoss: 1.853947\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 1.978555\n",
            "Train Epoch: 1 [41280/60000 (69%)]\tLoss: 1.987372\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 1.921819\n",
            "Train Epoch: 1 [41920/60000 (70%)]\tLoss: 1.958726\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 1.931005\n",
            "Train Epoch: 1 [42560/60000 (71%)]\tLoss: 1.808364\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 1.958254\n",
            "Train Epoch: 1 [43200/60000 (72%)]\tLoss: 1.922367\n",
            "Train Epoch: 1 [43520/60000 (73%)]\tLoss: 1.802612\n",
            "Train Epoch: 1 [43840/60000 (73%)]\tLoss: 1.918759\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 1.896019\n",
            "Train Epoch: 1 [44480/60000 (74%)]\tLoss: 1.788655\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.852661\n",
            "Train Epoch: 1 [45120/60000 (75%)]\tLoss: 1.847256\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 1.901845\n",
            "Train Epoch: 1 [45760/60000 (76%)]\tLoss: 1.753948\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 1.858980\n",
            "Train Epoch: 1 [46400/60000 (77%)]\tLoss: 1.815971\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 1.896248\n",
            "Train Epoch: 1 [47040/60000 (78%)]\tLoss: 1.780245\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 1.822574\n",
            "Train Epoch: 1 [47680/60000 (79%)]\tLoss: 1.723220\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.776099\n",
            "Train Epoch: 1 [48320/60000 (81%)]\tLoss: 1.761944\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 1.877043\n",
            "Train Epoch: 1 [48960/60000 (82%)]\tLoss: 1.762821\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 1.848605\n",
            "Train Epoch: 1 [49600/60000 (83%)]\tLoss: 1.648709\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 1.702061\n",
            "Train Epoch: 1 [50240/60000 (84%)]\tLoss: 1.779891\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 1.825302\n",
            "Train Epoch: 1 [50880/60000 (85%)]\tLoss: 1.757451\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.708673\n",
            "Train Epoch: 1 [51520/60000 (86%)]\tLoss: 1.781198\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 1.796253\n",
            "Train Epoch: 1 [52160/60000 (87%)]\tLoss: 1.631346\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 1.766291\n",
            "Train Epoch: 1 [52800/60000 (88%)]\tLoss: 1.755961\n",
            "Train Epoch: 1 [53120/60000 (89%)]\tLoss: 1.823910\n",
            "Train Epoch: 1 [53440/60000 (89%)]\tLoss: 1.734506\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 1.772098\n",
            "Train Epoch: 1 [54080/60000 (90%)]\tLoss: 1.687944\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 1.716489\n",
            "Train Epoch: 1 [54720/60000 (91%)]\tLoss: 1.655482\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 1.616660\n",
            "Train Epoch: 1 [55360/60000 (92%)]\tLoss: 1.625648\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 1.646507\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 1.654443\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 1.733173\n",
            "Train Epoch: 1 [56640/60000 (94%)]\tLoss: 1.612426\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 1.663473\n",
            "Train Epoch: 1 [57280/60000 (95%)]\tLoss: 1.657663\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.636275\n",
            "Train Epoch: 1 [57920/60000 (97%)]\tLoss: 1.624951\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 1.665727\n",
            "Train Epoch: 1 [58560/60000 (98%)]\tLoss: 1.571321\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 1.626418\n",
            "Train Epoch: 1 [59200/60000 (99%)]\tLoss: 1.447153\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 1.580674\n",
            "Train Epoch: 1 [59840/60000 (100%)]\tLoss: 1.621010\n",
            "\n",
            "Test set: Average loss: 1.5558, Accuracy: 6163/10000 (62%)\n",
            "\n",
            "conv1: torch.Size([32, 1, 3, 3])\n",
            "conv2: torch.Size([64, 32, 3, 3])\n",
            "fc1: torch.Size([128, 9216])\n",
            "fc1: torch.Size([10, 128])\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.702982\n",
            "Train Epoch: 2 [320/60000 (1%)]\tLoss: 1.638629\n",
            "Train Epoch: 2 [640/60000 (1%)]\tLoss: 1.458633\n",
            "Train Epoch: 2 [960/60000 (2%)]\tLoss: 1.570936\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 1.563970\n",
            "Train Epoch: 2 [1600/60000 (3%)]\tLoss: 1.444247\n",
            "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 1.605197\n",
            "Train Epoch: 2 [2240/60000 (4%)]\tLoss: 1.639420\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 1.691592\n",
            "Train Epoch: 2 [2880/60000 (5%)]\tLoss: 1.728967\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 1.593063\n",
            "Train Epoch: 2 [3520/60000 (6%)]\tLoss: 1.661739\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 1.482740\n",
            "Train Epoch: 2 [4160/60000 (7%)]\tLoss: 1.465183\n",
            "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 1.653739\n",
            "Train Epoch: 2 [4800/60000 (8%)]\tLoss: 1.543393\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 1.759636\n",
            "Train Epoch: 2 [5440/60000 (9%)]\tLoss: 1.633249\n",
            "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 1.551009\n",
            "Train Epoch: 2 [6080/60000 (10%)]\tLoss: 1.689798\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 1.567734\n",
            "Train Epoch: 2 [6720/60000 (11%)]\tLoss: 1.468899\n",
            "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 1.486939\n",
            "Train Epoch: 2 [7360/60000 (12%)]\tLoss: 1.602160\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 1.457119\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 1.577089\n",
            "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 1.556143\n",
            "Train Epoch: 2 [8640/60000 (14%)]\tLoss: 1.484400\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 1.611631\n",
            "Train Epoch: 2 [9280/60000 (15%)]\tLoss: 1.407740\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 1.530478\n",
            "Train Epoch: 2 [9920/60000 (17%)]\tLoss: 1.517797\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 1.580540\n",
            "Train Epoch: 2 [10560/60000 (18%)]\tLoss: 1.470984\n",
            "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 1.557938\n",
            "Train Epoch: 2 [11200/60000 (19%)]\tLoss: 1.401981\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 1.692240\n",
            "Train Epoch: 2 [11840/60000 (20%)]\tLoss: 1.548415\n",
            "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 1.477247\n",
            "Train Epoch: 2 [12480/60000 (21%)]\tLoss: 1.437208\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.443191\n",
            "Train Epoch: 2 [13120/60000 (22%)]\tLoss: 1.543817\n",
            "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 1.560680\n",
            "Train Epoch: 2 [13760/60000 (23%)]\tLoss: 1.575563\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 1.607548\n",
            "Train Epoch: 2 [14400/60000 (24%)]\tLoss: 1.455726\n",
            "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 1.436675\n",
            "Train Epoch: 2 [15040/60000 (25%)]\tLoss: 1.459806\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 1.438271\n",
            "Train Epoch: 2 [15680/60000 (26%)]\tLoss: 1.481588\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1.538074\n",
            "Train Epoch: 2 [16320/60000 (27%)]\tLoss: 1.399051\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 1.363874\n",
            "Train Epoch: 2 [16960/60000 (28%)]\tLoss: 1.517669\n",
            "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 1.389583\n",
            "Train Epoch: 2 [17600/60000 (29%)]\tLoss: 1.308730\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 1.276457\n",
            "Train Epoch: 2 [18240/60000 (30%)]\tLoss: 1.483907\n",
            "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 1.505382\n",
            "Train Epoch: 2 [18880/60000 (31%)]\tLoss: 1.470390\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.388246\n",
            "Train Epoch: 2 [19520/60000 (33%)]\tLoss: 1.369339\n",
            "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 1.639598\n",
            "Train Epoch: 2 [20160/60000 (34%)]\tLoss: 1.585635\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 1.310459\n",
            "Train Epoch: 2 [20800/60000 (35%)]\tLoss: 1.432177\n",
            "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 1.368065\n",
            "Train Epoch: 2 [21440/60000 (36%)]\tLoss: 1.550498\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 1.362174\n",
            "Train Epoch: 2 [22080/60000 (37%)]\tLoss: 1.457479\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 1.287960\n",
            "Train Epoch: 2 [22720/60000 (38%)]\tLoss: 1.329466\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 1.487042\n",
            "Train Epoch: 2 [23360/60000 (39%)]\tLoss: 1.449383\n",
            "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 1.399494\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 1.448230\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 1.561919\n",
            "Train Epoch: 2 [24640/60000 (41%)]\tLoss: 1.299550\n",
            "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 1.366928\n",
            "Train Epoch: 2 [25280/60000 (42%)]\tLoss: 1.293995\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.403623\n",
            "Train Epoch: 2 [25920/60000 (43%)]\tLoss: 1.459546\n",
            "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 1.395201\n",
            "Train Epoch: 2 [26560/60000 (44%)]\tLoss: 1.312012\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 1.370110\n",
            "Train Epoch: 2 [27200/60000 (45%)]\tLoss: 1.552524\n",
            "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 1.347709\n",
            "Train Epoch: 2 [27840/60000 (46%)]\tLoss: 1.560615\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 1.246316\n",
            "Train Epoch: 2 [28480/60000 (47%)]\tLoss: 1.498019\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 1.390523\n",
            "Train Epoch: 2 [29120/60000 (49%)]\tLoss: 1.411554\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 1.644837\n",
            "Train Epoch: 2 [29760/60000 (50%)]\tLoss: 1.433611\n",
            "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 1.441097\n",
            "Train Epoch: 2 [30400/60000 (51%)]\tLoss: 1.528547\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 1.407625\n",
            "Train Epoch: 2 [31040/60000 (52%)]\tLoss: 1.335218\n",
            "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 1.311267\n",
            "Train Epoch: 2 [31680/60000 (53%)]\tLoss: 1.454209\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.209957\n",
            "Train Epoch: 2 [32320/60000 (54%)]\tLoss: 1.382562\n",
            "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 1.352736\n",
            "Train Epoch: 2 [32960/60000 (55%)]\tLoss: 1.339068\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 1.301187\n",
            "Train Epoch: 2 [33600/60000 (56%)]\tLoss: 1.269254\n",
            "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 1.283606\n",
            "Train Epoch: 2 [34240/60000 (57%)]\tLoss: 1.287185\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 1.202882\n",
            "Train Epoch: 2 [34880/60000 (58%)]\tLoss: 1.324695\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 1.286163\n",
            "Train Epoch: 2 [35520/60000 (59%)]\tLoss: 1.146881\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 1.435250\n",
            "Train Epoch: 2 [36160/60000 (60%)]\tLoss: 1.296640\n",
            "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 1.281141\n",
            "Train Epoch: 2 [36800/60000 (61%)]\tLoss: 1.494431\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 1.269290\n",
            "Train Epoch: 2 [37440/60000 (62%)]\tLoss: 1.299137\n",
            "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 1.290052\n",
            "Train Epoch: 2 [38080/60000 (63%)]\tLoss: 1.256167\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.391023\n",
            "Train Epoch: 2 [38720/60000 (65%)]\tLoss: 1.252276\n",
            "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 1.193405\n",
            "Train Epoch: 2 [39360/60000 (66%)]\tLoss: 1.241282\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 1.348434\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.209177\n",
            "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 1.279811\n",
            "Train Epoch: 2 [40640/60000 (68%)]\tLoss: 1.001610\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 1.307598\n",
            "Train Epoch: 2 [41280/60000 (69%)]\tLoss: 1.508214\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 1.285450\n",
            "Train Epoch: 2 [41920/60000 (70%)]\tLoss: 1.410176\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 1.459939\n",
            "Train Epoch: 2 [42560/60000 (71%)]\tLoss: 1.190918\n",
            "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 1.387912\n",
            "Train Epoch: 2 [43200/60000 (72%)]\tLoss: 1.349552\n",
            "Train Epoch: 2 [43520/60000 (73%)]\tLoss: 1.201900\n",
            "Train Epoch: 2 [43840/60000 (73%)]\tLoss: 1.341182\n",
            "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 1.481890\n",
            "Train Epoch: 2 [44480/60000 (74%)]\tLoss: 1.118017\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 1.173940\n",
            "Train Epoch: 2 [45120/60000 (75%)]\tLoss: 1.264906\n",
            "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 1.373953\n",
            "Train Epoch: 2 [45760/60000 (76%)]\tLoss: 1.115651\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 1.228463\n",
            "Train Epoch: 2 [46400/60000 (77%)]\tLoss: 1.137520\n",
            "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 1.330892\n",
            "Train Epoch: 2 [47040/60000 (78%)]\tLoss: 1.128063\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 1.302616\n",
            "Train Epoch: 2 [47680/60000 (79%)]\tLoss: 1.139038\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.064945\n",
            "Train Epoch: 2 [48320/60000 (81%)]\tLoss: 1.183983\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 1.415604\n",
            "Train Epoch: 2 [48960/60000 (82%)]\tLoss: 1.194001\n",
            "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 1.251530\n",
            "Train Epoch: 2 [49600/60000 (83%)]\tLoss: 1.137927\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 1.079805\n",
            "Train Epoch: 2 [50240/60000 (84%)]\tLoss: 1.208699\n",
            "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 1.458883\n",
            "Train Epoch: 2 [50880/60000 (85%)]\tLoss: 1.228729\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.254285\n",
            "Train Epoch: 2 [51520/60000 (86%)]\tLoss: 1.273042\n",
            "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 1.293500\n",
            "Train Epoch: 2 [52160/60000 (87%)]\tLoss: 0.936534\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 1.388059\n",
            "Train Epoch: 2 [52800/60000 (88%)]\tLoss: 1.225639\n",
            "Train Epoch: 2 [53120/60000 (89%)]\tLoss: 1.325702\n",
            "Train Epoch: 2 [53440/60000 (89%)]\tLoss: 1.281151\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 1.258488\n",
            "Train Epoch: 2 [54080/60000 (90%)]\tLoss: 1.239820\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 1.332750\n",
            "Train Epoch: 2 [54720/60000 (91%)]\tLoss: 1.252475\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 1.157599\n",
            "Train Epoch: 2 [55360/60000 (92%)]\tLoss: 1.155256\n",
            "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 1.182798\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 1.324640\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 1.430168\n",
            "Train Epoch: 2 [56640/60000 (94%)]\tLoss: 1.054386\n",
            "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 1.398548\n",
            "Train Epoch: 2 [57280/60000 (95%)]\tLoss: 1.172210\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.186627\n",
            "Train Epoch: 2 [57920/60000 (97%)]\tLoss: 1.077493\n",
            "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 1.257076\n",
            "Train Epoch: 2 [58560/60000 (98%)]\tLoss: 1.235664\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 1.333231\n",
            "Train Epoch: 2 [59200/60000 (99%)]\tLoss: 1.095914\n",
            "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 1.426840\n",
            "Train Epoch: 2 [59840/60000 (100%)]\tLoss: 1.215057\n",
            "\n",
            "Test set: Average loss: 1.0907, Accuracy: 6766/10000 (68%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03f58390-36b9-43c7-93ae-63d8610509a9"
      },
      "source": [
        ""
      ],
      "id": "03f58390-36b9-43c7-93ae-63d8610509a9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50aec0b2-db69-4acb-bc73-fad7c2ca8a07"
      },
      "source": [
        ""
      ],
      "id": "50aec0b2-db69-4acb-bc73-fad7c2ca8a07",
      "execution_count": null,
      "outputs": []
    }
  ]
}